{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHP94D3+hM0+65qZfoUC26",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esvm/IF704-chatbot/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI0oKTw6LV1b"
      },
      "source": [
        "# Basic Instructions\n",
        "\n",
        "1. Create an account in [Kaggle](https://www.kaggle.com/)\n",
        "2. Go to your account (https://www.kaggle.com/<yourusername>/account)\n",
        "3. Generate a new API Token if you don't have one\n",
        "4. Upload the downloaded `kaggle.json` in this notebook folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmGQGxifEAZE"
      },
      "source": [
        "# Installing [Kaggle](https://www.kaggle.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxqoKeX36KER",
        "outputId": "2d48f066-6403-4d1c-c9be-d0075884e45e"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj1Adi-QH8sH"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udpxS0vtEVMP"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVSgRKK8JX4K"
      },
      "source": [
        "# Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLZJJSfaEb1K",
        "outputId": "8caa9709-878a-4d42-f0c8-42fecc9604ba"
      },
      "source": [
        "! kaggle datasets download -d stefanlarson/outofscope-intent-classification-dataset"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading outofscope-intent-classification-dataset.zip to /content\n",
            "\r  0% 0.00/285k [00:00<?, ?B/s]\n",
            "\r100% 285k/285k [00:00<00:00, 36.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0BsY_AoK4xC"
      },
      "source": [
        "if not os.path.exists('./dataset'):\n",
        "        os.makedirs('./dataset')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mhbGsTjKpb-"
      },
      "source": [
        "! mv outofscope-intent-classification-dataset.zip ./dataset"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kPyIe5GM_sw"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('./dataset/outofscope-intent-classification-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./dataset')"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHKZQwUUMDsO"
      },
      "source": [
        "# Setup Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxrVnG-qMHve",
        "outputId": "4710d5b6-34a2-458a-9958-a2b6adf7b0dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ignore words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# tokenize and vetorize text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# one-hot encoding labels\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# deep learning\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Conv2D\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH5dk--ZYLBA",
        "outputId": "6a06a4c1-c7d8-48ed-ffde-c03dd743247a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "words = set(stopwords.words(\"english\"))\n",
        "print(words)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'about', 'above', 'being', 'as', 'just', \"didn't\", 'd', 'to', \"wasn't\", 'any', 'you', 'himself', 'a', 'in', 'no', \"aren't\", 'his', 'wouldn', \"it's\", 'were', 'what', 'not', 'through', 'wasn', \"she's\", 've', 'myself', \"you'll\", 'haven', 'didn', 'if', 'him', \"don't\", 'am', 'out', \"mustn't\", 'can', 'too', 'been', 'such', 'itself', 'weren', \"you're\", 'its', 'was', 'had', 'our', 'both', 'couldn', 'now', 'there', 'or', 'which', 'where', 'with', \"haven't\", 'so', 'up', 't', 'their', 'into', 'most', 'he', 'those', 'o', 'these', 'because', 'by', 'them', 'i', 'mightn', \"hadn't\", 'over', 'shan', 'during', \"that'll\", 'than', 'doesn', \"doesn't\", 'other', 'do', 'for', 'on', \"isn't\", 'aren', 'whom', 'theirs', 'have', \"shouldn't\", \"wouldn't\", 'ma', 're', 'ours', 'the', 'of', 'own', \"you've\", 'yourselves', 'then', 'has', 'again', 'few', 'against', 'isn', 'ourselves', \"needn't\", 'having', 'll', 'while', 'm', 'an', 'hadn', 'is', 'does', 'and', \"hasn't\", 'nor', 'who', 'further', 's', 'shouldn', 'from', \"shan't\", 'themselves', 'her', 'won', 'how', 'it', 'we', 'herself', 'that', 'me', 'between', 'until', 'when', 'very', 'be', 'y', 'did', 'this', 'she', 'down', 'why', 'here', 'same', 'yours', 'needn', 'at', 'under', 'don', 'should', 'only', 'mustn', 'each', 'but', 'before', 'below', \"should've\", 'are', 'my', 'once', 'all', 'hasn', 'doing', 'hers', 'they', 'ain', 'more', 'will', \"you'd\", 'some', \"won't\", \"weren't\", \"couldn't\", 'your', 'after', \"mightn't\", 'off', 'yourself'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsyFZBzjL-u8"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmMPb-jYO4Z7"
      },
      "source": [
        "# Read movies conversations\n",
        "scopeTestJSON = pd.read_json(\"./dataset/is_test.json\")\n",
        "scopeTrainJSON = pd.read_json(\"./dataset/is_train.json\")\n",
        "scopeValJSON = pd.read_json(\"./dataset/is_val.json\")"
      ],
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48MERhzcMBr2"
      },
      "source": [
        "# scopeTestJSON[0] = scopeTestJSON[0].apply(lambda x: ' '.join([word for word in x.split() if word not in (words)]))\n",
        "# scopeTrainJSON[0] = scopeTestJSON[0].apply(lambda x: ' '.join([word for word in x.split() if word not in (words)]))\n",
        "# scopeValJSON[0] = scopeTestJSON[0].apply(lambda x: ' '.join([word for word in x.split() if word not in (words)]))\n",
        "\n",
        "# Extract only dialog texts\n",
        "scopeTestText = [str(line).strip() for line in scopeTestJSON[0]]\n",
        "scopeTrainText = [str(line).strip() for line in scopeTrainJSON[0]]\n",
        "\n",
        "modelText = scopeTrainText + scopeTestText\n",
        "scopeValText = [str(line).strip() for line in scopeValJSON[0]]"
      ],
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqs85PCOO7dd"
      },
      "source": [
        "# Extract only labels\n",
        "scopeTestLabels = [str(line).strip() for line in scopeTestJSON[1]]\n",
        "scopeTrainLabels = [str(line).strip() for line in scopeTrainJSON[1]]\n",
        "\n",
        "modelLabels = scopeTrainLabels + scopeTestLabels\n",
        "scopeValLabels = [str(line).strip() for line in scopeValJSON[1]]"
      ],
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-Z7oP817egw"
      },
      "source": [
        "# Tokenize words from dialogues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuDqVAoF7kTp"
      },
      "source": [
        "tok = Tokenizer()\n",
        "tok.fit_on_texts(modelText)\n",
        "wordIndex = tok.word_index"
      ],
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEYFVKXRAAcd"
      },
      "source": [
        "# Vetorizing dialogues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qStSx22BWjqI"
      },
      "source": [
        "modelTokens = tok.texts_to_sequences(modelText)\n",
        "\n",
        "maxVocabSize = len(wordIndex) + 1\n",
        "inputLength = 20 # max(map(lambda x: len(x), modelTokens))"
      ],
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHglV9RlcyVy",
        "outputId": "20ae8556-063f-47f5-a10c-cc832cdcb5ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputLength"
      ],
      "execution_count": 420,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 420
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW_BtOWZADHl"
      },
      "source": [
        "modelInput = pad_sequences(modelTokens, inputLength)\n",
        "\n",
        "validationTokens = tok.texts_to_sequences(scopeValText)\n",
        "validationInput = pad_sequences(validationTokens, inputLength)"
      ],
      "execution_count": 520,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3R0NnjQHz6R"
      },
      "source": [
        "# One-hot encoding labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIeRamqEH3fW"
      },
      "source": [
        "label_transformer = preprocessing.LabelEncoder()\n",
        "label_transformer.fit(modelLabels)\n",
        "\n",
        "encodedValidationLabels = label_transformer.transform(scopeValLabels)\n",
        "encodedModelLabels = label_transformer.transform(modelLabels)"
      ],
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LV-5eUAIgAq"
      },
      "source": [
        "categoricalValidationLabels = to_categorical(np.asarray(encodedValidationLabels))\n",
        "categoricalModelLabels = to_categorical(np.asarray(encodedModelLabels))"
      ],
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGM4BOLZINdt",
        "outputId": "12572ebb-118c-4698-96c2-1e2d9aaaca1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(categoricalModelLabels)"
      ],
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYV0PPL8Lzv-"
      },
      "source": [
        "# Split train data to isolate test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWVNMz9QL4SZ"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(modelInput, categoricalModelLabels, test_size=0.2, random_state=13)"
      ],
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUPErycqKNm4"
      },
      "source": [
        "# Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1LmcqnyKT3H"
      },
      "source": [
        "model = Sequential([\n",
        "  Embedding(maxVocabSize, 300, input_length=inputLength),                 \n",
        "  Conv1D(filters=32, kernel_size=8, activation='relu'),\n",
        "  MaxPooling1D(pool_size=3),\n",
        "  Flatten(),\n",
        "  Dense(180, activation='relu'),\n",
        "  Dense(150, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 509,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kes9ZIEPK6Ok",
        "outputId": "e6405388-4fb8-4d51-e9b0-1a72ff2379c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_21 (Embedding)     (None, 20, 300)           1787400   \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 13, 32)            76832     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_16 (MaxPooling (None, 4, 32)             0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 180)               23220     \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 150)               27150     \n",
            "=================================================================\n",
            "Total params: 1,914,602\n",
            "Trainable params: 1,914,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBbMVxoQLHRh",
        "outputId": "a67fb33f-976f-4cd9-87fb-d6fc5a803278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=6, verbose=1)"
      ],
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "488/488 [==============================] - 38s 76ms/step - loss: 3.4567 - accuracy: 0.2394\n",
            "Epoch 2/6\n",
            "488/488 [==============================] - 37s 76ms/step - loss: 0.9780 - accuracy: 0.7458\n",
            "Epoch 3/6\n",
            "488/488 [==============================] - 37s 76ms/step - loss: 0.4718 - accuracy: 0.8751\n",
            "Epoch 4/6\n",
            "488/488 [==============================] - 38s 77ms/step - loss: 0.3011 - accuracy: 0.9191\n",
            "Epoch 5/6\n",
            "488/488 [==============================] - 37s 77ms/step - loss: 0.2084 - accuracy: 0.9421\n",
            "Epoch 6/6\n",
            "488/488 [==============================] - 37s 76ms/step - loss: 0.1624 - accuracy: 0.9549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efcd37a9110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 511
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQyWt_S2OMzv",
        "outputId": "6458f6c3-abc9-4a69-eba2-a9fbc279a08b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(X_val, y_val)"
      ],
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "122/122 [==============================] - 1s 4ms/step - loss: 0.8799 - accuracy: 0.8079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8798507452011108, 0.8079487085342407]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cax0VHuaOOq2"
      },
      "source": [
        "predictions = model.predict(validationInput)"
      ],
      "execution_count": 521,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCa7Jkd7W4d9",
        "outputId": "e14d6727-e0c3-497b-bdf6-2da20a38eefa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def acc(y_true, y_pred):\n",
        "    return np.equal(np.argmax(y_true, axis=-1), np.argmax(y_pred, axis=-1)).mean()\n",
        "\n",
        "print(acc(categoricalValidationLabels, predictions))"
      ],
      "execution_count": 522,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7366666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUxH4BjNXNnI"
      },
      "source": [
        "def get_intent(sentence):\n",
        "  data = [[sentence]]\n",
        "  df = pd.DataFrame(data)\n",
        "  input = df[0]\n",
        "  input = tok.texts_to_sequences(input)\n",
        "  input = pad_sequences(input, inputLength)\n",
        "  prediction = model.predict(input)\n",
        "  # return np.argmin(prediction)\n",
        "  return modelLabels[np.where(encodedModelLabels == np.argmax(prediction))[0][0]]"
      ],
      "execution_count": 523,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq6hDKGOXU19",
        "outputId": "976f6102-044c-4c73-d0eb-9e81c1d76083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "get_intent(\"in spanish, meet me tomorrow is said how\")"
      ],
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'translate'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 524
        }
      ]
    }
  ]
}